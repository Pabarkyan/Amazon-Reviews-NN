{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0\n",
      "4.44.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import transformers\n",
    "print(tf.__version__)\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, SpatialDropout1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FICHERO_DATA = 'data/data_reviews.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(FICHERO_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reseñas</th>\n",
       "      <th>IA</th>\n",
       "      <th>longitud</th>\n",
       "      <th>longitud_promedio</th>\n",
       "      <th>palabras_unicas</th>\n",
       "      <th>signos_de_puntuación</th>\n",
       "      <th>frecuencia_pronombres</th>\n",
       "      <th>variedad_lexica</th>\n",
       "      <th>entropia_lexica</th>\n",
       "      <th>expresiones</th>\n",
       "      <th>tfidf</th>\n",
       "      <th>palabras_complejas</th>\n",
       "      <th>tecnicismos</th>\n",
       "      <th>polaridad</th>\n",
       "      <th>subjetividad</th>\n",
       "      <th>coherencia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Necesitaba un nuevo movil y me decidí por este...</td>\n",
       "      <td>0</td>\n",
       "      <td>297</td>\n",
       "      <td>4.066667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>5.267482</td>\n",
       "      <td>0</td>\n",
       "      <td>5.640761e-02</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Está en perfectas condiciones la batería al 10...</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>5.375000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>5.551115e-17</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Me llegó ayer el iPhone en perfectas condicion...</td>\n",
       "      <td>0</td>\n",
       "      <td>436</td>\n",
       "      <td>4.402439</td>\n",
       "      <td>0.695122</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.707317</td>\n",
       "      <td>5.710972</td>\n",
       "      <td>0</td>\n",
       "      <td>5.749596e-02</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Compré  un iPhone 12 a este vendedor y hace un...</td>\n",
       "      <td>0</td>\n",
       "      <td>657</td>\n",
       "      <td>4.124031</td>\n",
       "      <td>0.581395</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>5.880116</td>\n",
       "      <td>0</td>\n",
       "      <td>7.866846e-02</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.823529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Soy usuario de IPhone desde el principio. Teng...</td>\n",
       "      <td>0</td>\n",
       "      <td>596</td>\n",
       "      <td>4.109244</td>\n",
       "      <td>0.638655</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.655462</td>\n",
       "      <td>5.953860</td>\n",
       "      <td>0</td>\n",
       "      <td>7.357145e-02</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.953488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reseñas  IA  longitud  \\\n",
       "0  Necesitaba un nuevo movil y me decidí por este...   0       297   \n",
       "1  Está en perfectas condiciones la batería al 10...   0        99   \n",
       "2  Me llegó ayer el iPhone en perfectas condicion...   0       436   \n",
       "3  Compré  un iPhone 12 a este vendedor y hace un...   0       657   \n",
       "4  Soy usuario de IPhone desde el principio. Teng...   0       596   \n",
       "\n",
       "   longitud_promedio  palabras_unicas  signos_de_puntuación  \\\n",
       "0           4.066667         0.733333                     6   \n",
       "1           5.375000         1.000000                     2   \n",
       "2           4.402439         0.695122                     7   \n",
       "3           4.124031         0.581395                    10   \n",
       "4           4.109244         0.638655                    11   \n",
       "\n",
       "   frecuencia_pronombres  variedad_lexica  entropia_lexica  expresiones  \\\n",
       "0                      0         0.733333         5.267482            0   \n",
       "1                      0         1.000000         4.000000            0   \n",
       "2                      0         0.707317         5.710972            0   \n",
       "3                      1         0.604651         5.880116            0   \n",
       "4                      0         0.655462         5.953860            0   \n",
       "\n",
       "          tfidf  palabras_complejas  tecnicismos  polaridad  subjetividad  \\\n",
       "0  5.640761e-02                   3            0        0.0           0.0   \n",
       "1  5.551115e-17                   2            0        0.0           0.0   \n",
       "2  5.749596e-02                   5            0        0.0           0.0   \n",
       "3  7.866846e-02                   5            0        0.0           0.0   \n",
       "4  7.357145e-02                   4            0        0.0           0.0   \n",
       "\n",
       "   coherencia  \n",
       "0    0.920000  \n",
       "1    1.000000  \n",
       "2    0.857143  \n",
       "3    0.823529  \n",
       "4    0.953488  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['reseñas', 'IA', 'longitud', 'longitud_promedio', 'palabras_unicas',\n",
       "       'signos_de_puntuación', 'frecuencia_pronombres', 'variedad_lexica',\n",
       "       'entropia_lexica', 'expresiones', 'tfidf', 'palabras_complejas',\n",
       "       'tecnicismos', 'polaridad', 'subjetividad', 'coherencia'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# Función para limpiar el texto\n",
    "def limpiar_texto(texto):\n",
    "    texto = texto.lower()  # Convertir a minúsculas\n",
    "    texto = re.sub(r'\\d+', '', texto)  # Eliminar números\n",
    "    texto = re.sub(r'\\s+', ' ', texto)  # Eliminar espacios adicionales\n",
    "    texto = re.sub(r'[^\\w\\s]', '', texto)  # Eliminar caracteres especiales\n",
    "    return texto\n",
    "\n",
    "# Aplicar la limpieza de texto\n",
    "df['reseñas'] = df['reseñas'].apply(limpiar_texto)\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['reseñas'], df['IA'], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pabma\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Tokenización con BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenización del conjunto de entrenamiento y prueba\n",
    "train_encodings = tokenizer(X_train.tolist(), truncation=True, padding=True, max_length=128)\n",
    "test_encodings = tokenizer(X_test.tolist(), truncation=True, padding=True, max_length=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Convertir etiquetas a tensores\n",
    "train_labels = tf.convert_to_tensor(y_train.tolist())\n",
    "test_labels = tf.convert_to_tensor(y_test.tolist())\n",
    "\n",
    "# Crear datasets de TensorFlow\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    train_labels\n",
    ")).batch(16)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(test_encodings),\n",
    "    test_labels\n",
    ")).batch(16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:From c:\\Users\\pabma\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\pabma\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "183/183 [==============================] - 696s 4s/step - loss: 0.7407 - accuracy: 0.4976 - val_loss: 0.6961 - val_accuracy: 0.4658\n",
      "Epoch 2/3\n",
      "183/183 [==============================] - 639s 3s/step - loss: 0.7307 - accuracy: 0.4887 - val_loss: 0.6911 - val_accuracy: 0.5342\n",
      "Epoch 3/3\n",
      "183/183 [==============================] - 640s 3s/step - loss: 0.7333 - accuracy: 0.4897 - val_loss: 0.6921 - val_accuracy: 0.5342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x1e422cc4140>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TFBertForSequenceClassification\n",
    "import tensorflow as tf\n",
    "\n",
    "# Definir el modelo\n",
    "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "# Compilar el modelo con optimizador Adam\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(train_dataset, epochs=3, validation_data=test_dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 40s 877ms/step - loss: 0.6921 - accuracy: 0.5342\n",
      "Accuracy: 0.534246563911438\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_dataset)\n",
    "print(f'Accuracy: {accuracy}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
